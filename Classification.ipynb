{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5945b0b2-99d5-4447-b8e5-094fedc52964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ac97d2f-ae20-439f-8e5b-4a146c4bb773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/zera_2311ai06/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eb1c048-a8f6-45a5-8188-5eb8e84e7403",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "277d24424bd340c19acf7c25e6f81187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "torch.manual_seed(42)\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    load_in_4bit=True,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e69624e7-65db-44c6-a9d1-ff029ca24c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# # Login using e.g. `huggingface-cli login` to access this dataset\n",
    "train_ds = load_dataset(\"TheFinAI/finarg-ecc-auc_train\")\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "test_ds = load_dataset(\"TheFinAI/flare-finarg-ecc-auc_test\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "597223d5-ef8b-40a9-b0b7-774da90e9ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cb0fbf0-e3c8-4cb8-8609-2b0f6b4404b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "prefix = 'Classify the given text as claim or premise: '\n",
    "def preprocess(data):\n",
    "    data['input_ids']=tokenizer(data['text'],max_length=256,padding='max_length',return_tensors='pt',truncation=True).input_ids.clone().detach()\n",
    "    #labels=[0]*2\n",
    "    #labels[data['gold']]=1\n",
    "    #data['labels']=labels\n",
    "    data['labels']=data['gold']\n",
    "    return data\n",
    "\n",
    "process_train = train_ds.map(preprocess)\n",
    "process_train=process_train['train'].train_test_split(test_size=0.8)\n",
    "process_train=process_train['train'].train_test_split(test_size=0.2)\n",
    "process_test = test_ds.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b59fb547-ea1c-477c-a2d6-7ab2b39d66c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'query', 'answer', 'text', 'choices', 'gold', 'input_ids', 'labels'],\n",
       "        num_rows: 1240\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'query', 'answer', 'text', 'choices', 'gold', 'input_ids', 'labels'],\n",
       "        num_rows: 310\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "815607ab-dabc-4e6b-bb74-1d55416c8f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self,num_class=1):\n",
    "        super().__init__()\n",
    "        self.classification = nn.Sequential(\n",
    "            nn.Linear(256*4096,256),\n",
    "          \n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256,128),\n",
    "         \n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128,num_class),\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = x.flatten(1)        \n",
    "        return self.classification(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5975fe6-2d12-4c9d-862a-85b3581446cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_model = Classifier().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "239b17af-f51c-487c-bdcf-9ce4e5d065be",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params = cls_model.parameters(),lr=1e-5)\n",
    "loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d46dc63-176c-4702-a159-928d1f50f6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "import torch.functional as F\n",
    "\n",
    "torch.manual_seed(42)\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 8\n",
    "best_model=None\n",
    "best_score =0\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    cls_model.train()\n",
    "    decoder.eval()\n",
    "    train_loss=0\n",
    "    test_loss =0\n",
    "    \n",
    "    for i in tqdm(range(1,len(process_train['train']),BATCH_SIZE)):\n",
    "        input_ids = torch.tensor(process_train['train']['input_ids'][i:i+BATCH_SIZE]).squeeze(1).to('cuda')\n",
    "        labels = torch.tensor(process_train['train']['labels'][i:i+BATCH_SIZE]).float().to('cuda')\n",
    "        with torch.no_grad():\n",
    "            decoder_out = decoder(input_ids).last_hidden_state\n",
    "\n",
    "        #pred = cls_model(decoder_out.float())\n",
    "        pred = cls_model(decoder_out.float()).squeeze()\n",
    "        loss = loss_fn(pred,labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss+=loss.item()\n",
    "\n",
    "\n",
    "    total_train_loss = train_loss/(len(process_train['train'])//BATCH_SIZE)\n",
    "    \n",
    "\n",
    "    test_pred =[]\n",
    "    test_real =[]\n",
    "    \n",
    "    cls_model.eval()\n",
    "    for i in tqdm(range(1,len(process_train['test']),BATCH_SIZE)):\n",
    "        test_input_ids = torch.tensor(process_train['test']['input_ids'][i:i+BATCH_SIZE]).squeeze(1).to('cuda')\n",
    "        #test_labels = torch.tensor(process_train['test']['labels'][i:i+BATCH_SIZE]).float().to('cuda')\n",
    "        test_labels = torch.tensor(process_train['test']['labels'][i:i+BATCH_SIZE]).float().to('cuda')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            decoder_out_test = decoder(test_input_ids).last_hidden_state\n",
    "            #pred_test = cls_model(decoder_out_test.float())\n",
    "            pred_test=cls_model(decoder_out_test.float()).squeeze()\n",
    "            loss_test = loss_fn(pred_test,test_labels)\n",
    "        test_loss+=loss_test.item()\n",
    "        \n",
    "        #test_pred.extend(pred_test.softmax(dim=1).argmax(dim=1).cpu().numpy())\n",
    "        test_pred.extend(pred_test.sigmoid().cpu().numpy()>0.7)\n",
    "        test_real.extend(test_labels.cpu().numpy())\n",
    "        \n",
    "    #print(test_pred)\n",
    "    #print(test_real)\n",
    "    total_eval_loss = test_loss/(len(process_train['test'])//BATCH_SIZE)\n",
    "    acc = accuracy_score(test_real,test_pred)\n",
    "    f1  = f1_score(test_real,test_pred)\n",
    "    if f1>best_score:\n",
    "        best_model = cls_model\n",
    "        best_score = f1\n",
    "\n",
    "    print('*'*100)\n",
    "    print(f'Epoch:{epoch+1}\\nTrain Loss:{total_train_loss:.4f} \\nTest Loss:{total_eval_loss:.4f} \\t\\t Accuracy:{acc:.4f} \\t\\t F1 Score:{f1:.4f}\\t\\t Best Score:{best_score:.4f}')\n",
    "    print('*'*100)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "894e1ff0-72e4-4e7f-b50c-36e0bbf22703",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred =[]\n",
    "test_real =[]\n",
    "    \n",
    "best_model.eval()\n",
    "for i in tqdm(range(1,len(process_test['test']),BATCH_SIZE)):\n",
    "    test_input_ids = torch.tensor(process_test['test']['input_ids'][i:i+BATCH_SIZE]).squeeze(1).to('cuda')\n",
    "    test_labels = torch.tensor(process_test['test']['labels'][i:i+BATCH_SIZE]).float().to('cuda')\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        decoder_out_test = decoder(test_input_ids).last_hidden_state\n",
    "        #pred_test = best_model(decoder_out_test.float())\n",
    "        pred_test=cls_model(decoder_out_test.float()).squeeze()\n",
    "        loss_test = loss_fn(pred_test,test_labels)\n",
    "    test_loss+=loss_test.item()\n",
    "        \n",
    "    # test_pred.extend(pred_test.argmax(dim=1).cpu().numpy())\n",
    "    # test_real.extend(test_labels.argmax(dim=1).cpu().numpy())\n",
    "    test_pred.extend(pred_test.sigmoid().cpu().numpy()>0.5)\n",
    "    test_real.extend(test_labels.cpu().numpy())\n",
    "        \n",
    "\n",
    "total_test_loss = test_loss/(len(process_train['test'])//BATCH_SIZE)\n",
    "acc = accuracy_score(test_real,test_pred)\n",
    "f1  = f1_score(test_real,test_pred)\n",
    "\n",
    "print('*'*90)\n",
    "print(f'Epoch:{epoch+1}\\nTest Loss:{total_test_loss:.4f} \\t\\t Accuracy:{acc:.4f} \\t\\t F1 Score:{f1:.4f}')\n",
    "print('*'*90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e66b84-c3ba-4df8-9fd2-6a8a57dfe68b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:zera]",
   "language": "python",
   "name": "conda-env-zera-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
